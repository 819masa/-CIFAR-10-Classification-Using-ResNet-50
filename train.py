import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torch.nn.functional as F
import numpy as np
import random
import time
import wandb
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from model import get_model

hyperparameters = {
    "project_name": "clasification of cifar-10 by ResNet50",
    "experiment_name": "ResNet50_Stem_TrivialAug_AdamW_50ep_TTA_ramdomerasing", # å®Ÿé¨“å
    "note": "AdamW (lr=0.001, wd=1e-2). Modified Stem + TrivialAugment.no mixup and add TTA,ramdomerasing.", # æ–½ç­–ãƒ¡ãƒ¢
    "architecture": "ResNet50_CIFAR_Optimized",
    "dataset": "CIFAR-10",
    "epochs": 50,              # å‹•ä½œç¢ºèªã®ãŸã‚å°‘ãªã‚ã«è¨­å®šã—ã¦ã„ã¾ã™ã€‚
    "batch_size": 128,
    "learning_rate": 0.001,
    "weight_decay": 1e-2,      # AdamWç”¨ã«å¤‰æ›´
    "momentum": 0.9,
    "optimizer": "AdamW",
    "scheduler": "CosineAnnealingLR", # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’è¿½åŠ 
    "seed": 42,
    "resize": 32,              # CIFAR-10ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    "use_mixup": False,       # Mixupã‚’ä½¿ã†ã‹ã‚¹ã‚¤ãƒƒãƒ
    "mixup_alpha": 1.0,      # æ··ãœå…·åˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ1.0ãŒæ¨™æº–ï¼‰
    "mixup_epochs": 0,      # ã€Œæœ€åˆã®40ã‚¨ãƒãƒƒã‚¯ã ã‘ã€Mixupã™ã‚‹ï¼ˆæ®‹ã‚Šã®10ã¯æ™®é€šã«å­¦ç¿’ï¼‰
}



def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

set_seed(config.seed)



# --- 6. å­¦ç¿’ãƒ»è©•ä¾¡é–¢æ•°ã®å®šç¾© ---


def train_one_epoch(epoch, model, loader, optimizer, criterion, device, config): # configã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´
    model.train()
    sum_loss = 0.0
    correct = 0
    total = 0

    for i, (images, labels) in enumerate(loader):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        # === Mixup ã®åˆ¤å®š ===
        # è¨­å®šãŒONã€ã‹ã¤ æŒ‡å®šã‚¨ãƒãƒƒã‚¯ä»¥å†…ãªã‚‰ Mixup ã‚’å®Ÿè¡Œ
        if config.use_mixup and epoch <= config.mixup_epochs:

            # 1. Betaåˆ†å¸ƒã‹ã‚‰æ··ãœã‚‹æ¯”ç‡ (lambda) ã‚’æ±ºã‚ã‚‹
            # alpha=1.0 ãªã‚‰ 0~1 ã®é–“ã§å‡ç­‰ã«é¸ã°ã‚Œã‚‹
            lam = np.random.beta(config.mixup_alpha, config.mixup_alpha)

            # 2. ãƒãƒƒãƒå†…ã®ç”»åƒã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œã‚‹
            batch_size = images.size(0)
            index = torch.randperm(batch_size).to(device)

            # 3. ç”»åƒã‚’æ··ãœã‚‹ï¼ ( mixed_x = Î»x + (1-Î»)x_shuffle )
            mixed_images = lam * images + (1 - lam) * images[index]

            # 4. ãƒ¢ãƒ‡ãƒ«ã«é€šã™
            outputs = model(mixed_images)

            # 5. Lossã‚’æ··ãœã‚‹ï¼ ( Loss = Î» * Loss(y1) + (1-Î») * Loss(y2) )
            # ãƒ©ãƒ™ãƒ«è‡ªä½“ã‚’æ··ãœã‚‹ã®ã§ã¯ãªãã€ãã‚Œãã‚Œã®æ­£è§£ã«å¯¾ã™ã‚‹Lossã‚’è¨ˆç®—ã—ã¦æ··ãœã¾ã™
            loss = lam * criterion(outputs, labels) + (1 - lam) * criterion(outputs, labels[index])

        else:
            # === é€šå¸¸å­¦ç¿’ (å¾ŒåŠã‚¨ãƒãƒƒã‚¯ ã¾ãŸã¯ Mixup OFFæ™‚) ===
            outputs = model(images)
            loss = criterion(outputs, labels)

        # --- ä»¥ä¸‹ã¯å…±é€š ---
        loss.backward()
        optimizer.step()

        sum_loss += loss.item()

        # ç²¾åº¦ã®è¨ˆç®—ï¼ˆMixupä¸­ã¯æ­£ç¢ºãªæ­£è§£ç‡ãŒå‡ºãªã„ã®ã§ã€ä¸»ãƒ©ãƒ™ãƒ«ã§è¿‘ä¼¼è¨ˆç®—ï¼‰
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    avg_loss = sum_loss / len(loader)
    acc = correct / total
    current_lr = optimizer.param_groups[0]['lr']

    # ãƒ­ã‚°è¡¨ç¤ºï¼ˆMixupä¸­ã‹ã©ã†ã‹åˆ†ã‹ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
    mode = "Mixup" if (config.use_mixup and epoch <= config.mixup_epochs) else "Normal"
    print(f"[Train] Epoch {epoch} ({mode}): Loss={avg_loss:.4f}, Acc={acc:.4f}, LR={current_lr:.6f}")

    wandb.log({
        "epoch": epoch,
        "train/loss": avg_loss,
        "train/accuracy": acc,
        "train/learning_rate": current_lr,
        "mixup_mode": 1 if mode == "Mixup" else 0 # ã‚°ãƒ©ãƒ•ã§åˆ‡ã‚Šæ›¿ã‚ã‚ŠãŒè¦‹ãˆã‚‹ã‚ˆã†ã«
    })



def evaluate(epoch, model, loader, criterion, device, log_results=True):
    model.eval()
    sum_loss = 0.0
    all_preds = []
    all_labels = []
    # èª¤åˆ†é¡ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
    misclassified_images = []
    misclassified_preds = []
    misclassified_labels = []

    with torch.no_grad():
        for images, labels in loader:
            images_dev = images.to(device)
            labels_dev = labels.to(device)

            outputs = model(images_dev)
            loss = criterion(outputs, labels_dev)
            sum_loss += loss.item()

            _, predicted = outputs.max(1)

            # ãƒ‡ãƒ¼ã‚¿ã‚’CPUã«æˆ»ã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ 
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # ---  èª¤åˆ†é¡ã‚µãƒ³ãƒ—ãƒ«ã®åé›† ---
            if len(misclassified_images) < 32:
                mask = predicted != labels_dev
                if mask.any():
                    # ä¿®æ­£: imagesï¼ˆCPUï¼‰ã§ã¯ãªã images_devï¼ˆGPUï¼‰ã‚’ä½¿ã†
                    # GPUåŒå£«ã§è¨ˆç®—ã—ã¦ã‹ã‚‰ .cpu() ã§æˆ»ã™ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
                    wrong_imgs = images_dev[mask].cpu()
                    wrong_preds = predicted[mask].cpu()
                    wrong_labels = labels_dev[mask].cpu()

                    for img, p, l in zip(wrong_imgs, wrong_preds, wrong_labels):
                        if len(misclassified_images) < 32:
                            misclassified_images.append(img)
                            misclassified_preds.append(p.item())
                            misclassified_labels.append(l.item())

    # æŒ‡æ¨™è¨ˆç®—
    avg_loss = sum_loss / len(loader)
    acc = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)

    print(f"[Val] Epoch {epoch}: Loss={avg_loss:.4f}, Acc={acc:.4f}, F1={f1:.4f}")

    if log_results:
        log_dict = {
            "epoch": epoch,
            "val/loss": avg_loss,
            "val/accuracy": acc,
            "val/precision": precision,
            "val/recall": recall,
            "val/f1_score": f1,
        }

        # æœ€çµ‚ã‚¨ãƒãƒƒã‚¯ã®ã¿è©³ç´°ãªã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’è¨˜éŒ²
        if epoch == config.epochs:
            # 1. æ··åŒè¡Œåˆ—
            log_dict["val/confusion_matrix"] = wandb.plot.confusion_matrix(
                probs=None,
                y_true=all_labels,
                preds=all_preds,
                class_names=classes
            )

            # 2. èª¤åˆ†é¡ã‚µãƒ³ãƒ—ãƒ«ã®ç”»åƒè¨˜éŒ²
            wandb_images = []
            for img, p, l in zip(misclassified_images, misclassified_preds, misclassified_labels):
                img = torch.clamp(img, 0, 1)
                caption = f"True: {classes[l]} / Pred: {classes[p]}"
                wandb_images.append(wandb.Image(img, caption=caption))

            log_dict["val/misclassified_examples"] = wandb_images

        wandb.log(log_dict)

    return acc

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# --- è©³ç´°æŒ‡æ¨™å¯¾å¿œç‰ˆ TTAè©•ä¾¡é–¢æ•° ---
def evaluate_with_tta(model, loader, device):
    model.eval()
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã¨æ­£è§£ã‚’è²¯ã‚ã‚‹ãƒªã‚¹ãƒˆ
    all_preds = []
    all_labels = []
    
    print("\nğŸš€ Starting TTA Evaluation (Original + Horizontal Flip)...")
    
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.to(device)

            # 1. ãã®ã¾ã¾äºˆæ¸¬
            outputs1 = model(images)
            probs1 = F.softmax(outputs1, dim=1)

            # 2. å·¦å³åè»¢ã—ã¦äºˆæ¸¬
            images_flipped = torch.flip(images, dims=[3])
            outputs2 = model(images_flipped)
            probs2 = F.softmax(outputs2, dim=1)

            # 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (å¹³å‡)
            avg_probs = (probs1 + probs2) / 2.0
            
            # äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’å–å¾—
            _, predicted = torch.max(avg_probs.data, 1)
            
            # ãƒªã‚¹ãƒˆã«è¿½åŠ  (CPUã«æˆ»ã—ã¦numpyåŒ–)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # --- æŒ‡æ¨™ã®è¨ˆç®— (Macroå¹³å‡) ---
    acc = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)

    print(f"--------------------------------------------------")
    print(f"âœ… TTA Result:")
    print(f"   Accuracy : {acc:.4f}")
    print(f"   F1 Score : {f1:.4f}")
    print(f"   Precision: {precision:.4f}")
    print(f"   Recall   : {recall:.4f}")
    print(f"--------------------------------------------------")
    
    # W&Bã«è¨˜éŒ² (é€šå¸¸ã®valã¨åŒºåˆ¥ã™ã‚‹ãŸã‚ã« tta/ ã‚’ã¤ã‘ã‚‹)
    wandb.log({
        "test/tta_accuracy": acc,
        "test/tta_precision": precision,
        "test/tta_recall": recall,
        "test/tta_f1_score": f1
    })
    
    return acc



